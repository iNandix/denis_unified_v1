# AUDITORÃA TÃ‰CNICA + PLAN HARDENING PRE-PROD
**Denis Control Plane v3.1.0**  
**Fecha:** 2026-02-18  
**Arquitecto:** IZQUIERDA  
**Estado:** Pre-ProducciÃ³n

---

## WS1: THREAT MODEL & RISK REGISTER

| ID | Riesgo | Tipo | Impacto | Prob | SeÃ±ales de DetecciÃ³n | MitigaciÃ³n EspecÃ­fica |
|----|--------|------|---------|------|---------------------|----------------------|
| R01 | **Loop infinito** por X-Denis-Hop bypass | Seguridad | ðŸ”´ Alto | ðŸŸ¡ Media | `X-Denis-Hop: 99` en logs, CPU 100%, latencia exponencial | Middleware rechaza hop > 3; test automÃ¡tico de loops; alerta si hop count anÃ³malo |
| R02 | **InyecciÃ³n de prompts** vÃ­a /chat | Seguridad | ðŸ”´ Alto | ðŸŸ¢ Baja | Patrones de jailbreak en logs de chat; tokens anÃ³malos | SanitizaciÃ³n de input; rate limiting por IP; shadow mode para patrones sospechosos |
| R03 | **Abuso de APIs** (DoS) | Seguridad | ðŸŸ  Medio | ðŸŸ¡ Media | 429s masivos en logs; requests > 1000/min por IP | Rate limiting Redis-backed (60 req/min IP, 300 req/min user); circuit breaker automÃ¡tico |
| R04 | **Secrets leak** en logs/graph | Seguridad | ðŸ”´ Alto | ðŸŸ¢ Baja | Regex scan de logs buscando `sk-`, `Bearer`; auditorÃ­a de DecisionTrace.context | Redactor automÃ¡tico en middleware; campos sensibles excluidos de DecisionTrace; alerta si token aparece en log |
| R05 | **SSRF** vÃ­a HASS integration | Seguridad | ðŸŸ  Medio | ðŸŸ¢ Baja | URLs internas (169.254, 10.0.0.0/8) en requests a HASS | Whitelist de dominios HASS permitidos; validaciÃ³n de URL antes de conexiÃ³n; sandbox de red |
| R06 | **Graph down** - SSoT no disponible | Fiabilidad | ðŸ”´ Alto | ðŸŸ¡ Media | Neo4j connection errors; queries timeout > 5s; DecisionTrace no escribe | Cache TTL 60s de provider chain; fail-open a config local; alerta PagerDuty si graph caÃ­do > 30s |
| R07 | **HASS flapping** (conexiÃ³n inestable) | Fiabilidad | ðŸŸ¡ Bajo | ðŸŸ¡ Media | Reconexiones WebSocket > 5/min; entidades aparecen/desaparecen | Exponential backoff en reconnect (max 5 min); modo "stub" automÃ¡tico si flapping > 3 ciclos; cache de Ãºltimo estado conocido 5 min |
| R08 | **Nodomac stale** - snapshot viejo | Fiabilidad | ðŸŸ  Medio | ðŸŸ¢ Baja | `last_scan` > 24h; overlay_scan no ejecutado; files not found | Alerta si last_scan > 6h; fallback a filesystem scan local si manifest stale; Control Room trigger automÃ¡tico de re-scan |
| R09 | **Overload** - throughput excesivo | Fiabilidad | ðŸ”´ Alto | ðŸŸ¡ Media | Latencia p95 > 2s; queue depth > 100; memory > 80% | Autoscaling (si k8s) o rate limiting estricto; degradaciÃ³n a local provider; 503 con Retry-After header |
| R10 | **Memory leak** en denis_agent | Fiabilidad | ðŸŸ  Medio | ðŸŸ¢ Baja | RSS crece > 100MB/hour; OOM kills en logs; GC pressure | LÃ­mite de memoria en systemd/docker (1GB); restart automÃ¡tico OOM; mÃ©tricas de heap expuestas en /telemetry |
| R11 | **Config drift** - flags inconsistentes | OperaciÃ³n | ðŸŸ  Medio | ðŸŸ¢ Baja | FeatureFlag en Graph != env var; comportamiento inesperado | Preflight check en startup valida consistencia env vs graph; alerta si drift detectado; source of truth Ãºnico (Graph) |
| R12 | **Silent failures** - errores no reportados | OperaciÃ³n | ðŸ”´ Alto | ðŸŸ¡ Media | MÃ©tricas de error rate bajas pero usuarios reportan problemas; DecisionTrace missing | Health check externo (synthetic) cada 1 min; correlaciÃ³n DecisionTrace vs requests totales; alerta si trace missing > 1% |

### Riesgos Priorizados (Top 5)
1. **R01** Loop infinito (Seguridad crÃ­tica)
2. **R06** Graph down (Fiabilidad core)
3. **R04** Secrets leak (Seguridad compliance)
4. **R12** Silent failures (OperaciÃ³n invisible)
5. **R09** Overload (Fiabilidad escalabilidad)

---

## WS2: FAILURE GAME DAYS (DRILLS)

### Game Day 1: Cloud CaÃ­do 24h
**Escenario:** ISP principal caÃ­do, solo nodomac conectado vÃ­a Tailscale

**QuÃ© se rompe:**
- nodo1 inaccesible desde internet
- nodo2 (GPU) inaccesible
- Solo nodomac funciona localmente

**Comportamiento esperado:**
- denis_agent en nodomac entra modo "local only"
- /chat usa local_chat exclusivamente
- /health muestra "nodo1: down, nodo2: down"
- /hass/entities usa stub local

**Frontend muestra:**
- Banner rojo: "Modo supervivencia - Solo funcionalidad local"
- Chat funciona pero limitado (sin providers externos)
- Care dashboard vacÃ­o o modo demo

**MÃ©tricas/alertas:**
- ðŸ”´ CRITICAL: `denis_node_offline{nodo="nodo1"} > 300` (5 min)
- ðŸ”´ CRITICAL: `denis_node_offline{nodo="nodo2"} > 300`
- ðŸŸ¡ WARNING: `denis_fallback_rate == 1.0` (100% local)

**ResoluciÃ³n:**
- ISP restaurado
- Health check pasa en nodo1/nodo2
- Gradual restoration de providers

---

### Game Day 2: Graph Lento / Inconsistencias
**Escenario:** Neo4j degradado, queries tardan 10s+, algunos timeouts

**QuÃ© se rompe:**
- DecisionTrace writes fallan o tardan
- Provider chain reads lentos
- /health tarda en responder

**Comportamiento esperado:**
- Cache de provider chain (60s TTL) sirve requests
- DecisionTrace: fail-soft (no bloquea request)
- /health retorna cached state con "stale: true"

**Frontend muestra:**
- Banner amarillo: "Datos pueden estar desactualizados"
- Chat funciona (cache) pero mÃ¡s lento
- Ops dashboard marca "Graph degraded"

**MÃ©tricas/alertas:**
- ðŸ”´ CRITICAL: `denis_graph_latency_p95 > 5000` (5s)
- ðŸŸ¡ WARNING: `denis_graph_cache_hit_rate > 0.9` (excesivo caching)
- ðŸŸ¡ WARNING: `denis_decision_trace_dropped > 0`

**ResoluciÃ³n:**
- Neo4j reiniciado / optimizado
- Cache hit rate vuelve a normal (< 0.5)
- DecisionTrace writes restaurados

---

### Game Day 3: Loop Storm con X-Denis-Hop
**Escenario:** Bug en frontend causa requests recursivos (Aâ†’Bâ†’A)

**QuÃ© se rompe:**
- X-Denis-Hop incrementa indefinidamente
- CPU usage explota
- Latencia crece exponencialmente

**Comportamiento esperado:**
- Middleware detecta hop > 3, rechaza con 400
- Rate limiter bloquea IP despuÃ©s de 10 errores 400
- Alerta inmediata a seguridad

**Frontend muestra:**
- 400 Bad Request con mensaje: "Loop detected"
- Bloqueo temporal del usuario/IP

**MÃ©tricas/alertas:**
- ðŸ”´ CRITICAL: `denis_loop_detected_rate > 0` (inmediato)
- ðŸ”´ CRITICAL: `http_requests_400_total` spike
- ðŸ”´ SECURITY: Alerta PagerDuty + email a security@denis

**ResoluciÃ³n:**
- Bug de frontend identificado y fixeado
- IP desbloqueado manualmente
- Post-mortem publicado

---

### Game Day 4: Nodomac Solo con Snapshot Viejo
**Escenario:** nodomac aislado, Ãºltimo overlay scan > 48h

**QuÃ© se rompe:**
- Filesystem entries desactualizados
- Paths pueden no existir
- Manifests stale

**Comportamiento esperado:**
- /overlay/resolve intenta paths, falla silenciosamente
- Fallback a filesystem scan directo (lento pero funciona)
- Control Room intenta re-scan cada 1h

**Frontend muestra:**
- Banner amarillo: "Ãndice de archivos desactualizado"
- BÃºsquedas lentas (direct FS scan)
- Algunos archivos "not found" si fueron movidos

**MÃ©tricas/alertas:**
- ðŸŸ¡ WARNING: `denis_overlay_scan_stale_hours > 24`
- ðŸŸ¡ WARNING: `denis_overlay_fs_fallback_rate > 0.1`
- ðŸ”´ CRITICAL: `denis_overlay_not_found_rate > 0.05` (5%)

**ResoluciÃ³n:**
- Conectividad restaurada
- Control Room ejecuta overlay_scan manual
- Snapshot regenerado

---

### Game Day 5: ExplosiÃ³n de Latencia
**Escenario:** Latencia p95 salta de 200ms a 5s subitamente

**QuÃ© se rompe:**
- User experience degradado
- Timeouts en frontend
- Circuit breakers se activan

**Comportamiento esperado:**
- Circuit breaker abre despuÃ©s de 5 errores consecutivos
- Fallback a local provider
- Rate limiting se activa para proteger

**Frontend muestra:**
- Spinner largo â†’ timeout â†’ "Servicio lento, intentando modo local"
- Mensajes aparecen con delay
- Banner de degradaciÃ³n

**MÃ©tricas/alertas:**
- ðŸ”´ CRITICAL: `denis_latency_p95 > 2000` (2s)
- ðŸ”´ CRITICAL: `denis_circuit_breaker_open == 1`
- ðŸŸ¡ WARNING: `denis_fallback_rate > 0.5` (50%)

**ResoluciÃ³n:**
- Identificar causa (provider lento, red congestionada)
- Ajustar timeouts o cambiar provider preferido
- Circuit breaker cierra gradualmente

---

### Game Day 6: Rate Limit Sostenido
**Escenario:** Usuario legÃ­timo supera 60 req/min durante 10 minutos

**QuÃ© se rompe:**
- Usuario bloqueado temporalmente
- Potencial pÃ©rdida de requests legÃ­timos

**Comportamiento esperado:**
- HTTP 429 con Retry-After: 60 header
- Usuario puede continuar despuÃ©s de cooldown
- No afecta a otros usuarios

**Frontend muestra:**
- "Rate limit exceeded. Please slow down."
- Retry automÃ¡tico con backoff exponencial

**MÃ©tricas/alertas:**
- ðŸŸ¡ WARNING: `http_requests_429_total` spike
- ðŸŸ¡ INFO: `denis_rate_limit_hit{user="xxx"}` (no alerta, solo log)

**ResoluciÃ³n:**
- Usuario reduce frecuencia
- O: contacta Ops para aumentar lÃ­mite (premium)

---

### Game Day 7: Secrets Flood
**Escenario:** Bug accidental loggea API keys en stdout

**QuÃ© se rompe:**
- Potencial exposiciÃ³n de secrets
- Compliance violation
- Necesidad rotaciÃ³n de keys

**Comportamiento esperado:**
- Alerta inmediata por patrÃ³n `sk-` en logs
- Logs redirigidos a storage seguro (no stdout)
- Servicio NO se detiene (availability > secrecy)

**Frontend muestra:**
- Nada (transparente)

**MÃ©tricas/alertas:**
- ðŸ”´ CRITICAL: `denis_secrets_detected_in_logs > 0`
- ðŸ”´ SECURITY: PagerDuty inmediato
- ðŸ”´ SECURITY: Email a security@denis

**ResoluciÃ³n:**
- Bug fixeado
- Logs sanitizados
- RotaciÃ³n de API keys afectadas
- Post-mortem + proceso mejorado

---

### Game Day 8: Partial Brownout
**Escenario:** DegradaciÃ³n parcial - solo Chat CP funciona, resto lento

**QuÃ© se rompe:**
- /chat funciona normal
- /health, /hass, /telemetry tardan 10s+
- Graph writes fallan intermitentemente

**Comportamiento esperado:**
- Chat prioritario (ingreso principal)
- Ops endpoints usan cache extendido (5 min)
- DecisionTrace: buffer en memoria, flush cuando Graph vuelva

**Frontend muestra:**
- Chat funciona perfecto
- Ops dashboard "stale data" warning
- Care dashboard "temporarily unavailable"

**MÃ©tricas/alertas:**
- ðŸŸ¡ WARNING: `denis_partial_degradation == 1`
- ðŸŸ¡ WARNING: `denis_graph_write_buffer_size > 100`
- ðŸŸ¢ INFO: `denis_core_functional == 1` (chat OK)

**ResoluciÃ³n:**
- Graph restaurado
- Buffer de DecisionTrace flushado
- Cache TTL vuelve a normal (60s)

---

## WS3: CONFIG & FEATURE FLAGS STRATEGY

### JerarquÃ­a de ConfiguraciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         RUNTIME (mÃ¡xima)           â”‚  â† graph FeatureFlag (hot reload)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         ENVIRONMENT                 â”‚  â† env vars (restart required)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         CONFIG FILE                 â”‚  â† config.yaml (restart required)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         DEFAULTS (mÃ­nima)          â”‚  â† cÃ³digo fuente
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ResoluciÃ³n de conflictos: runtime > env > file > defaults
```

### 10 Flags/Configs CrÃ­ticos

| Config | Source | Default | Rango | QuÃ© Rompe si Mal | ValidaciÃ³n Preflight |
|--------|--------|---------|-------|------------------|---------------------|
| `DENIS_ENABLE_CHAT_CP` | env | false | bool | Chat no funciona | Check: chat module importable |
| `DENIS_CHAT_CP_SHADOW_MODE` | env | false | bool | No logs de debugging | Warning si true en prod |
| `DENIS_CHAT_CP_GRAPH_WRITE` | env | false | bool | Sin audit trail | Warning si false en prod |
| `DENIS_RATE_LIMIT_RPM` | env | 60 | 10-1000 | Abuso o bloqueo legÃ­timo | Test: 61 req/min -> 429 |
| `DENIS_HOP_MAX_DEPTH` | env | 3 | 1-5 | Loops o rechazos falsos | Test: hop=4 -> 400 |
| `DENIS_CACHE_TTL_SECONDS` | graph | 60 | 0-300 | Stale data o performance | Check: cache hit rate < 0.8 |
| `DENIS_CIRCUIT_BREAKER_THRESHOLD` | graph | 5 | 1-20 | Falsa apertura o cascada | Test: 5 errores -> circuit open |
| `DENIS_PROVIDER_CHAIN` | graph | ["anthropic","openai","local"] | array | Routing incorrecto | Check: todos los providers existen |
| `DENIS_LOCAL_MODE_BUDGET` | graph | 1000 | 0-unlimited | Coste excesivo o denegaciÃ³n | Alerta si > 80% consumido |
| `DENIS_HASS_ENABLED` | env | false | bool | Intentos de conexiÃ³n fallidos | Check: HASS_URL vÃ¡lido si true |

### Preflight / Doctor Checks

```python
# En startup de denis_agent
def preflight_checks():
    checks = []
    
    # 1. Graph connectivity
    checks.append(check_graph_connection())
    
    # 2. FeatureFlag consistency
    checks.append(check_flag_consistency())
    
    # 3. Secrets availability (sin loggear valores)
    checks.append(check_secrets_present())
    
    # 4. Provider chain valid
    checks.append(check_provider_chain())
    
    # 5. Hop middleware loaded
    checks.append(check_hop_middleware())
    
    # 6. Rate limiter functional
    checks.append(check_rate_limiter())
    
    # 7. Cache operational
    checks.append(check_cache())
    
    # 8. DecisionTrace writable
    checks.append(check_graph_write())
    
    # Resultado
    if all(c.passed for c in checks):
        logger.info("âœ… All preflight checks passed")
        return True
    else:
        for c in checks:
            if not c.passed:
                logger.error(f"âŒ Preflight failed: {c.name} - {c.error}")
        return False
```

---

## WS4: STARTUP, SHUTDOWN & DEGRADE PATHS

### Secuencia de Arranque

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STARTUP SEQUENCE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. ENV LOADING (500ms)
   â”œâ”€ Load .env
   â”œâ”€ Validate critical vars present (not values!)
   â””â”€ FAIL if NEO4J_URI missing (no puede funcionar sin Graph)

2. PREFLIGHT CHECKS (2s)
   â”œâ”€ Graph connectivity test
   â”œâ”€ FeatureFlag consistency check
   â”œâ”€ Secrets availability check
   â””â”€ FAIL si check crÃ­tico falla

3. CORE INITIALIZATION (3s)
   â”œâ”€ Redis connection (cache)
   â”œâ”€ Graph schema validation
   â”œâ”€ Provider chain load
   â””â”€ Middleware stack setup

4. SERVICE DISCOVERY (1s)
   â”œâ”€ nodomac heartbeat
   â”œâ”€ nodo2 health check
   â””â”€ HASS connectivity (if enabled)

5. API SERVER START (1s)
   â”œâ”€ FastAPI app init
   â”œâ”€ Router registration
   â”œâ”€ Middleware binding
   â””â”€ Listen on :9999

Total: ~8s max
```

### Shutdown Limpio

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SHUTDOWN SEQUENCE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. SIGTERM received
   â””â”€ Set shutdown flag

2. DRAIN CONNECTIONS (30s timeout)
   â”œâ”€ Stop accepting new requests
   â”œâ”€ Wait for in-flight requests
   â””â”€ 503 on new requests during drain

3. FLUSH DECISIONTRACE BUFFER (5s)
   â”œâ”€ Write pending traces to Graph
   â””â”€ Log "X traces flushed" or "Y traces dropped"

4. CLOSE CONNECTIONS
   â”œâ”€ Redis disconnect
   â”œâ”€ Graph disconnect
   â””â”€ HASS WebSocket close

5. EXIT
   â””â”€ Code 0 (clean) or 1 (dirty if timeout)
```

### Caminos de DegradaciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 DEGRADATION PATHS                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SANO (100%)
â”œâ”€ Graph: âœ…
â”œâ”€ Providers: Todos disponibles
â”œâ”€ Cache: Hit rate ~40%
â””â”€ Estado: ðŸŸ¢ Healthy

DEGRADADO NIVEL 1 (Graph lento/cachÃ©)
â”œâ”€ Graph: âš ï¸ Latencia > 1s
â”œâ”€ Action: Cache TTL extendido a 5 min
â”œâ”€ Providers: Normal
â””â”€ Estado: ðŸŸ¡ Degraded (cached)

DEGRADADO NIVEL 2 (Providers caÃ­dos)
â”œâ”€ Graph: âœ…
â”œâ”€ Providers: ðŸ”´ Todos caÃ­dos
â”œâ”€ Action: Fallback a local_chat
â””â”€ Estado: ðŸŸ¡ Degraded (local mode)

DEGRADADO NIVEL 3 (Graph caÃ­do + local)
â”œâ”€ Graph: ðŸ”´ Unreachable
â”œâ”€ Providers: ðŸ”´ Todos caÃ­dos  
â”œâ”€ Action: Local config + stub responses
â””â”€ Estado: ðŸŸ  Critical (survival mode)

BLOQUEADO (Loop detected)
â”œâ”€ X-Denis-Hop: > 3
â”œâ”€ Action: 400 Bad Request
â””â”€ Estado: ðŸ”´ Blocked (security)
```

### SeÃ±ales de Sistema Sano vs Riesgo

**SANO ðŸŸ¢:**
- /health retorna < 100ms
- Error rate < 1%
- Graph latency < 200ms
- DecisionTrace write success > 99%
- All providers healthy OR fallback rate < 10%

**RIESGO ðŸŸ¡:**
- /health > 500ms
- Error rate 1-5%
- Graph latency 200-1000ms
- Cache hit rate > 80% (excesivo)
- Fallback rate 10-50%

**CRÃTICO ðŸ”´:**
- /health > 2s o 503
- Error rate > 5%
- Graph down > 30s
- Fallback rate > 50%
- Circuit breaker open

---

## WS5: OPERABILITY CHECKLIST (PRE-PROD)

### Observabilidad

| Ãtem | CÃ³mo Verificar | Evidencia |
|------|----------------|-----------|
| **Logs estructurados** | `journalctl -u denis-agent -o json` | JSON con fields: timestamp, level, request_id, endpoint |
| **MÃ©tricas Prometheus** | `curl localhost:9999/metrics` | Output exposition format vÃ¡lido |
| **DecisionTrace en Graph** | `MATCH (d:Decision) RETURN count(d)` | Count > 0 despuÃ©s de requests |
| **Distributed tracing** | Headers X-Denis-Request-ID en logs | Mismo ID en todos los logs de un request |
| **Health endpoint** | `curl /health` | < 100ms, status field present |

### Alertas

| Ãtem | CÃ³mo Verificar | Evidencia |
|------|----------------|-----------|
| **PagerDuty integrado** | Trigger alerta de prueba | PD recibe alerta, responde ACK |
| **Slack integrado** | Trigger warning de prueba | Mensaje en #denis-alerts |
| **Alertas crÃ­ticas** | Simular graph down | Alerta < 30s, incluye runbook link |
| **Alertas ruidosas** | Revisar Ãºltimas 24h | < 5 alertas falsas |
| **Escalation path** | Documento en wiki | PÃ¡gina "On-call playbook" existe |

### Logs

| Ãtem | CÃ³mo Verificar | Evidencia |
|------|----------------|-----------|
| **No PII en logs** | Grep por emails/nombres | 0 matches |
| **No secrets en logs** | Grep por `sk-`, `Bearer` | 0 matches |
| **Log rotation** | `ls -la /var/log/denis/` | Files < 100MB, timestamps recientes |
| **Log retention** | PolÃ­tica documentada | 30 dÃ­as definido en Loki/Splunk |
| **Log levels** | Check ERROR/WARN ratio | < 1% ERROR, < 10% WARN |

### Backups/Snapshots

| Ãtem | CÃ³mo Verificar | Evidencia |
|------|----------------|-----------|
| **Graph backup** | `ls /backups/neo4j/` | Backup < 24h old |
| **SQLite backup** | `ls /backups/nodomac.db/` | Backup < 24h old |
| **Config backup** | `git log --oneline -5` | Ãšltimo commit < 1 semana |
| **Snapshot test** | Restore en staging | Funciona en < 30 min |
| **Backup encryption** | `file backup.tar.gz` | GPG encrypted o similar |

### Runbooks

| Ãtem | CÃ³mo Verificar | Evidencia |
|------|----------------|-----------|
| **On-call playbook** | `docs/runbook.md` | Existe, tiene 5+ procedimientos |
| **Game Days ejecutados** | Log de ejercicios | 8/8 Game Days completados |
| **Incident response** | Template en wiki | Template con roles, comunicaciÃ³n, timeline |
| **Escalation contacts** | PÃ¡gina "Contacts" | Lista con phone/Slack/email |
| **Rollback procedures** | Por cada PR en backlog | PR-1..PR-8 tienen rollback section |

### Tests CrÃ­ticos

| Ãtem | CÃ³mo Verificar | Evidencia |
|------|----------------|-----------|
| **Unit tests** | `pytest tests/unit/ -q` | Pass > 90% |
| **Integration tests** | `pytest tests/integration/ -q` | Pass > 80% |
| **E2E tests** | `pytest tests/e2e/ -q` | Pass > 70% |
| **Load test** | `k6 run load_test.js` | Soporta 100 req/s sin errores |
| **Failover test** | Script de Game Day 1 | Sistema funciona en modo local |
| **Anti-loop test** | Script de Game Day 3 | Rechaza hop > 3 correctamente |
| **Secrets redaction test** | Grep de logs | 0 secrets leaked |

---

## WS6: COST & TOKEN GOVERNANCE

### PolÃ­tica de Budgets

| Fase | Budget Mensual | QuÃ© Incluye | QuÃ© Excluye | AcciÃ³n si Excedido |
|------|---------------|-------------|-------------|-------------------|
| **P0** | $0 (local only) | Local provider, cache hits | Todos los providers externos | Block all external calls |
| **P0.5** | $100 (shadow) | Shadow mode logging, minimal real calls | Full production traffic | Switch to shadow mode |
| **P1** | $1000 (production) | Full production traffic | Exceso por abuso | Rate limiting estricto + alerta |
| **P2+** | $5000+ (scale) | Multi-region, backups, analytics | Experimentos sin ROI review | Budget approval required |

### Egress Modes

| Mode | DescripciÃ³n | CuÃ¡ndo Usar | CÃ³mo Activar |
|------|-------------|-------------|--------------|
| **OFF** | Solo local provider | Emergencia, incidente de coste | `DENIS_EGRESS_MODE=off` |
| **SHADOW** | Logs calls pero no ejecuta | Testing, validaciÃ³n | `DENIS_EGRESS_MODE=shadow` |
| **ON** | OperaciÃ³n normal | ProducciÃ³n normal | `DENIS_EGRESS_MODE=on` (default P1) |

### Overrides Manuales

```bash
# Emergencia: apagar todo egress inmediatamente
curl -X POST http://nodo1:9999/admin/egress \
  -H "Authorization: Bearer $ADMIN_TOKEN" \
  -d '{"mode": "off", "reason": "budget exceeded", "duration_minutes": 60}'

# Resultado: 200 OK, mode: off, all external providers disabled
```

### MÃ©tricas de Coste

| MÃ©trica | Tipo | DescripciÃ³n | Alerta |
|---------|------|-------------|--------|
| `denis_cost_usd_today` | Gauge | Coste acumulado hoy | ðŸŸ¡ > 80% budget daily |
| `denis_cost_usd_this_month` | Gauge | Coste acumulado mes | ðŸ”´ > 90% budget monthly |
| `denis_tokens_consumed_total` | Counter | Tokens totales consumidos | ðŸŸ¡ > 10M tokens/day |
| `denis_external_calls_total` | Counter | Calls a providers externos | ðŸŸ¡ > 10k calls/hour |
| `denis_cost_per_request_usd` | Gauge | Coste promedio por request | ðŸŸ¡ > $0.01/request |

### Kill Switch Operacional

```python
# En denis_agent, check cada minuto
if cost_today > DAILY_BUDGET * 0.9:
    logger.warning("Approaching daily budget limit, throttling...")
    enable_strict_rate_limiting()

if cost_today > DAILY_BUDGET:
    logger.critical("DAILY BUDGET EXCEEDED - EGRESS DISABLED")
    set_egress_mode("off")
    alert_pagerduty("Cost budget exceeded, egress disabled")
    
    # Auto-restore next day
    schedule_restore(next_day_utc)
```

### Dashboard en Nodo2 (Frontend)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COST DASHBOARD                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Today: $45.20 / $100 (45%) ðŸŸ¢          â”‚
â”‚  This Month: $890 / $1000 (89%) ðŸŸ¡      â”‚
â”‚                                         â”‚
â”‚  Tokens: 2.3M consumed today            â”‚
â”‚  Avg cost/req: $0.003                   â”‚
â”‚                                         â”‚
â”‚  [ðŸ”´ EMERGENCY SHUTDOWN]                â”‚
â”‚  (Requires admin confirmation)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## WS7: FRAGILITY ANALYSIS & QUICK WINS

### Top 5 Puntos MÃ¡s FrÃ¡giles Hoy

1. **Graph es SPOF**
   - Por quÃ©: Sin Graph, no hay provider chain, no hay DecisionTrace
   - Impacto: ðŸ”´ CrÃ­tico
   - Quick Win: Cache extendido + fallback a config local

2. **Sin rate limiting**
   - Por quÃ©: Cualquier IP puede hacer DoS
   - Impacto: ðŸ”´ CrÃ­tico
   - Quick Win: In-memory rate limit (60 req/min)

3. **Secrets en cÃ³digo/env**
   - Por quÃ©: Riesgo de leak en logs/repos
   - Impacto: ðŸ”´ CrÃ­tico
   - Quick Win: MigraciÃ³n a keyring/os.environ solo

4. **No circuit breaker**
   - Por quÃ©: Cascada de fallos si provider lento
   - Impacto: ðŸŸ  Medio
   - Quick Win: Simple threshold (5 errores -> open)

5. **Observabilidad dÃ©bil**
   - Por quÃ©: Silent failures posibles
   - Impacto: ðŸŸ  Medio
   - Quick Win: Health check sintÃ©tico cada 1 min

### 5 Small Wins TÃ©cnicos de Alto Impacto

| # | Win | Tiempo | Impacto | CÃ³mo Verificar |
|---|-----|--------|---------|----------------|
| 1 | **Cache provider chain 5 min** | 2h | ðŸŸ¢ Alto | Graph down, chat sigue funcionando |
| 2 | **Rate limiting 60 req/min** | 4h | ðŸŸ¢ Alto | 61 requests -> 429 |
| 3 | **Health check sintÃ©tico** | 3h | ðŸŸ¢ Alto | Alerta si /health tarda > 5s |
| 4 | **Log redaction regex** | 2h | ðŸŸ¢ Alto | `sk-xxx` nunca aparece en logs |
| 5 | **Circuit breaker threshold=5** | 6h | ðŸŸ¡ Medio | 5 errores -> fallback automÃ¡tico |

---

## GO/NO-GO CRITERIA FOR P1

### MUST HAVE (Sin esto, NO vamos a P1)

- [ ] **R01** Loop protection testeado y pasando
- [ ] **R04** Secrets redaction implementado
- [ ] **R06** Graph fail-open con cache > 5 min
- [ ] **Rate limiting** activo (60 req/min)
- [ ] **Health checks** reales (no stubs)
- [ ] **DecisionTrace** escribiendo 100% requests
- [ ] **Alertas crÃ­ticas** configuradas (PagerDuty)
- [ ] **Runbooks** para 8 Game Days
- [ ] **Backup strategy** documentada y testeada
- [ ] **Cost monitoring** dashboard funcional

### SHOULD HAVE (Mejor tener, pero no bloquea)

- [ ] Circuit breaker (R04)
- [ ] HASS integration real (PR-2)
- [ ] MÃ©tricas Prometheus reales (PR-3)
- [ ] JWT auth (PR-6)
- [ ] Testing automatizado CI/CD (PR-7)

### NICE TO HAVE (P2+)

- [ ] Multi-region
- [ ] Advanced analytics
- [ ] ML-based anomaly detection
- [ ] Automated rollback
- [ ] Chaos engineering automatizado

---

## DECISIÃ“N FINAL

**Estado actual:** P0.5 STAGING âœ…  
**PrÃ³ximo milestone:** P1 PRODUCTION  
**Bloqueadores crÃ­ticos:** 0 (con small wins implementados)  

**RecomendaciÃ³n:** 
- Implementar 5 small wins (1-2 dÃ­as)
- Ejecutar 8 Game Days (1 semana)
- Validar Go/No-Go checklist
- **Go para P1** si todos los MUST HAVE pasan

**Riesgo residual:** Medio-Bajo con mitigaciones implementadas

**Firma:** IZQUIERDA  
**Fecha:** 2026-02-18  
**VersiÃ³n:** v1.0
